<!doctype html>

<html lang="en" class="h-100">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta content="index, follow" name="robots">
  <meta name="generator" content="Hugo 0.77.0" />
  <link rel="stylesheet" href="https://juliagpu.org/css/bootstrap.min.css">

  
  <link rel="stylesheet" href="/highlight.css">
  <script src="/highlight.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <style>
    .hljs {
      padding: 0;
      background: none;
  }
  </style>

  
  
  
  <title>CUDAnative.jl 3.0 and CuArrays.jl 2.0 · JuliaGPU</title>
  <style>
.container {
  max-width: 700px;
}
#nav-border {
  border-bottom: 1px solid #212529;
}
#main {
  margin-top: 1em;
  margin-bottom: 4em;
}
#home-jumbotron {
  background-color: inherit;
}
#footer .container {
  padding: 1em 0;
}
#footer a {
  color: inherit;
  text-decoration: underline;
}
.font-125 {
  font-size: 125%;
}
.tag-btn {
  margin-bottom: 0.3em;
}
pre {
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  padding: 16px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  background-color: transparent;
  border-radius: 0;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 4px;
}
img,
iframe,
embed,
video,
audio {
  max-width: 100%;
}
.card-img,
.card-img-top,
.card-img-bottom {
  width: initial;
}
</style>

</head>

  <body class="d-flex flex-column h-100">
    <div id="nav-border" class="container">
  <nav class="navbar navbar-expand-lg navbar-light justify-content-center">
    
    
    <ul class="navbar-nav">
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/">
              
                
                <i data-feather="home"></i> 
              
              Home
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item active">
            <a class="nav-link" href="/post/">
              
                
                <i data-feather="file-text"></i> 
              
              Blog
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/learn/">
              
                
                <i data-feather="book-open"></i> 
              
              Learn
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/cuda/">
              
              NVIDIA CUDA
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/rocm/">
              
              AMD ROCm
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/oneapi/">
              
              Intel oneAPI
            </a>
          </li>
        
      
        
        
        
        
        
        

        
          <li class="nav-item ">
            <a class="nav-link" href="/other/">
              
              Other
            </a>
          </li>
        
      
    </ul>
  </nav>
</div>

    <div class="container">
      <main id="main">
        

<h1>CUDAnative.jl 3.0 and CuArrays.jl 2.0</h1>



<i data-feather="calendar"></i> <time datetime="2020-03-25">Mar 25, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Tim Besard


<br><br>

    <p>This release of the Julia CUDA stack contains some exciting new features: automatic
installation of CUDA using artifacts, full support for GPU method redefinitions, and
experimental support for multitasking and multithreading. The release is technically
breaking, but most end-users should not be affected.</p>
<h2 id="api-changes">API changes</h2>
<p>Changes to certain APIs require these releases to be breaking, however, most users should
not be affected and chances are you can just bump your Compat entries without any additional
changes. Flux.jl users will have to wait a little longer though, as the package uses
non-public APIs that have changed and <a href="https://github.com/FluxML/Flux.jl/pull/1050">requires an
update</a>.</p>
<h2 id="artifacts">Artifacts</h2>
<p>CUDA and its dependencies will now be automatically installed using artifacts generated by
BinaryBuilder.jl. This greatly improves usability, and only requires a functioning NVIDIA
driver:</p>
<pre><code class="language-julia-repl">julia&gt; ENV[&quot;JULIA_DEBUG&quot;] = &quot;CUDAnative&quot;

julia&gt; using CUDAnative

julia&gt; CUDAnative.version()
┌ Debug: Trying to use artifacts...
└ @ CUDAnative CUDAnative/src/bindeps.jl:52
┌ Debug: Using CUDA 10.2.89 from an artifact at /depot/artifacts/...
└ @ CUDAnative CUDAnative/src/bindeps.jl:108
v&quot;10.2.89&quot;
</code></pre>
<p>Use of a local installation is still possible by setting the environment variable
<code>JULIA_CUDA_USE_BINARYBUILDER</code> to false. For more details, refer to <a href="https://juliagpu.gitlab.io/CUDA.jl/installation/overview/">the
documentation</a>.</p>
<p>Relevant PRs: <a href="https://github.com/JuliaGPU/CUDAnative.jl/pull/492">CUDAnative.jl#492</a> and <a href="https://github.com/JuliaGPU/CuArrays.jl/pull/490">CuArrays.jl#490</a></p>
<h2 id="method-redefinitions">Method redefinitions</h2>
<p>CUDAnative 3.0 now fully supports method redefinitions, commonly referred to as <a href="https://github.com/JuliaLang/julia/issues/265">Julia
issue #265</a>, and makes it possible to use
interactive programming tools like Revise.jl:</p>
<pre><code class="language-julia-repl">julia&gt; child() = 0
julia&gt; parent() = (@cuprintln(child()); return)
julia&gt; @cuda parent()
0

julia&gt; parent() = (@cuprintln(child() + 1); return)
julia&gt; @cuda parent()
1


julia&gt; child() = 1
julia&gt; @cuda parent()
2
</code></pre>
<p>Relevant PRs: <a href="https://github.com/JuliaGPU/CUDAnative.jl/pull/581">CUDAnative.jl#581</a></p>
<h2 id="experimental-multitasking-and-multithreading">Experimental: Multitasking and multithreading</h2>
<p>With CUDAnative 3.0 and CuArrays 2.0 you can now use Julia tasks and threads to organize
your code. In combination with CUDA streams, this makes it possible to execute kernels and
other GPU operations in parallel:</p>
<pre><code class="language-julia">@sync begin
    function my_expensive_kernel()
        return
    end
    @async @cuda stream=CuStream() my_expensive_kernel()
    @async @cuda stream=CuStream() my_expensive_kernel()
end
</code></pre>
<p>Every task, whether it runs on a separate thread or not, can work with a different
device, as well as independently work with CUDA libraries like CUBLAS and CUFFT.</p>
<p>Note that this support is experimental, and lacks certain features to be fully effective.
For one, the CuArrays memory allocator is not device-aware, and it is currently not possible
to configure the CUDA stream for operations like map or broadcast.</p>
<p>Relevant PRs: <a href="https://github.com/JuliaGPU/CUDAnative.jl/pull/609">CUDAnative.jl#609</a> and
<a href="https://github.com/JuliaGPU/CuArrays.jl/pull/645">CuArrays.jl#645</a></p>
<h2 id="minor-changes">Minor changes</h2>
<p>GPU kernels are now name-mangled like C++, which offers better integration with NVIDIA tools
(<a href="https://github.com/JuliaGPU/CUDAnative.jl/pull/559">CUDAnative.jl#559</a>).</p>
<p>A better N-dimensional <code>mapreducedim!</code> kernel, properly integrating with all Base interfaces
(<a href="https://github.com/JuliaGPU/CuArrays.jl/pull/602">CuArrays.jl#602</a> and
<a href="https://github.com/JuliaGPU/GPUArrays.jl/pull/246">GPUArrays#246</a>).</p>
<p>A <code>CuIterator</code> type for batching arrays to the GPU (by @jrevels,
<a href="https://github.com/JuliaGPU/CuArrays.jl/pull/467">CuArrays.jl#467</a>).</p>
<p>Integration with Base&rsquo;s 5-arg <code>mul!</code> (by @haampie,
<a href="https://github.com/JuliaGPU/CuArrays.jl/pull/641">CuArrays.jl#641</a> and
<a href="https://github.com/JuliaGPU/GPUArrays.jl/pull/253">GPUArrays#253</a>).</p>
<p>Integration with Cthulhu.jl for interactive inspection of generated code
(<a href="https://github.com/JuliaGPU/CUDAnative.jl/issues/597">CUDAnative.jl#597</a>).</p>
<h2 id="known-issues">Known issues</h2>
<p>With a release as big as this one there&rsquo;s bound to be some bugs, e.g., with the
installation of artifacts on exotic systems, or due to the many changes to make the
libraries thread-safe. If you need absolute stability, please wait for a point release.</p>
<p>There are also some known issues. CUDAnative is currently not compatible with Julia 1.5 due
to Base compiler changes (<a href="https://github.com/JuliaLang/julia/issues/34993">julia#34993</a>),
the new <code>mapreducedim!</code> kernel appears to be slower in some cases
(<a href="https://github.com/JuliaGPU/CuArrays.jl/issues/611">CuArrays.jl#611</a>), and there are some
remaining thread-safety issues when using the non-default memory pool
(<a href="https://github.com/JuliaGPU/CuArrays.jl/issues/647">CuArrays.jl#647</a>).</p>



      </main>
    </div>
    
<footer id="footer" class="mt-auto text-center text-muted">
  <div class="container">
    Made with <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/zwbetz-gh/vanilla-bootstrap-hugo-theme">Vanilla</a>
  </div>
</footer>

    <script src="https://juliagpu.org/js/feather.min.js"></script>
<script>
  feather.replace()
</script>


    
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-154489943-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  </body>
</html>
