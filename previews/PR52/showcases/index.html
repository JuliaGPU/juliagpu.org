<!doctype html>
<html lang="en" class=h-100>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
  <meta content="index, follow" name=robots>
  <link rel="icon" href="/previews/PR52/assets/favicon.ico">
  <link rel="alternate" type="application/rss+xml" href="/previews/PR52/post/index.xml" title="RSS Feed for JuliaGPU">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/css/bootstrap.min.css">
   <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/styles/default.min.css">
 

  <link rel="stylesheet" href="/previews/PR52/css/style.css">

  
  
    <title>Showcases ⋅ JuliaGPU</title>
  
</head>
<body class="d-flex flex-column h-100">
  <div id=nav-border class=container>
    <nav class="navbar navbar-expand-sm navbar-light">
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
            aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle
navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-center" id="navbarNav">
            <ul class=navbar-nav>
                <li class="nav-item ">
                    <a class=nav-link href="/previews/PR52/"><i data-feather=home></i> Home</a>
                </li>
                <li class="nav-item ">
                    <a class=nav-link href="/previews/PR52/post/"><i data-feather=file-text></i> Blog</a>
                </li>
                <li class="nav-item active">
                    <a class=nav-link href="/previews/PR52/showcases/"><i data-feather=star></i> Showcases</a>
                </li>
                <li class="nav-item ">
                    <a class=nav-link href="/previews/PR52/learn/"><i data-feather=book-open></i> Learn</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle " href="#" id="backendDropdown"
                        role="button" data-bs-toggle="dropdown" aria-expanded="false">
                        <i data-feather=cpu></i> Backends
                    </a>
                    <div class="dropdown-menu" aria-labelledby="backendDropdown">
                        <a class="dropdown-item " href="/previews/PR52/backends/cuda/">CUDA</a>
                        <a class="dropdown-item " href="/previews/PR52/backends/rocm/">ROCm</a>
                        <a class="dropdown-item " href="/previews/PR52/backends/oneapi/">oneAPI</a>
                        <a class="dropdown-item " href="/previews/PR52/backends/metal/">Metal</a>
                        <a class="dropdown-item " href="/previews/PR52/backends/opencl/">OpenCL</a>
                    </div>
                </li>
            </ul>
        </div>
    </nav>
</div>


  <div class="container">
    <main id=main>

    
<!-- Content appended here -->

<h1 id="showcases"><a href="#showcases" class="header-anchor">Showcases</a></h1>
<p>The Julia language, combined with its powerful GPU ecosystem, enables developers and researchers to tackle demanding computational problems with unprecedented productivity and performance. With <strong>over <a href="https://juliahub.com/ui/Packages/General/GPUArrays#dependents">600 packages</a></strong> leveraging Julia&#39;s GPU capabilities, the ecosystem spans machine learning, scientific simulation, quantum computing, and more.</p>
<p>Here are some highlights showcasing the versatility and power of Julia on GPUs.</p>
<h2 id="fluxjl_elegant_machine_learning"><a href="#fluxjl_elegant_machine_learning" class="header-anchor">Flux.jl: Elegant Machine Learning</a></h2>
<p><strong><a href="https://github.com/FluxML/Flux.jl">Flux.jl</a></strong> is Julia&#39;s premier machine learning library, known for its flexibility and tight integration with the Julia ecosystem. Moving computations from the CPU to the GPU is often trivial, unlocking massive speedups for training deep learning models.</p>
<p>Here&#39;s an example of a simple multi-layer perceptron &#40;MLP&#41; model trained on a synthetic dataset using Flux.jl. The network is defined and trained on the GPU with minimal code changes, by simply applying the <code>device</code> function to the model and data.</p>
<pre><code class="language-julia">using Flux
using CUDA # Or AMDGPU, Metal

# Function to move data and model to the GPU
device &#61; gpu_device&#40;&#41;

# Define our model, and upload it to the GPU
model &#61; Chain&#40;
    # multi-layer perceptron with one hidden layer of size 3
    Dense&#40;2 &#61;&gt; 3, tanh&#41;,
    BatchNorm&#40;3&#41;,
    Dense&#40;3 &#61;&gt; 2&#41;&#41; |&gt; device

# Generate some data on the CPU
noisy &#61; rand&#40;Float32, 2, 1000&#41;
truth &#61; &#91;xor&#40;col&#91;1&#93;&gt;0.5, col&#91;2&#93;&gt;0.5&#41; for col in eachcol&#40;noisy&#41;&#93;

# Training loop &#40;processing the data in batches&#41;
target &#61; Flux.onehotbatch&#40;truth, &#91;true, false&#93;&#41;
loader &#61; Flux.DataLoader&#40;&#40;noisy, target&#41;, batchsize&#61;64, shuffle&#61;true&#41;
for epoch in 1:1_000
    for xy_cpu in loader
        # Upload the batch to the GPU
        x, y &#61; xy_cpu |&gt; device
        loss, grads &#61; Flux.withgradient&#40;model&#41; do m
            y_hat &#61; m&#40;x&#41;
            Flux.logitcrossentropy&#40;y_hat, y&#41;
        end
        Flux.update&#33;&#40;opt_state, model, grads&#91;1&#93;&#41;
    end
end</code></pre>
<h2 id="diffeqgpujl_accelerating_scientific_simulation"><a href="#diffeqgpujl_accelerating_scientific_simulation" class="header-anchor">DiffEqGPU.jl: Accelerating Scientific Simulation</a></h2>
<p>Part of the acclaimed <strong><a href="https://diffeq.sciml.ai/stable/">DifferentialEquations.jl</a></strong> &#40;SciML&#41; ecosystem, <strong><a href="https://github.com/JuliaDiffEq/DiffEqGPU.jl">DiffEqGPU.jl</a></strong> provides highly optimized GPU kernels for solving large ensembles of differential equations &#40;ODEs, SDEs, etc.&#41; in parallel. This enables massive speedups for parameter sweeps, uncertainty quantification, and simulating complex systems found in biology, physics, and engineering.</p>
<p>As an example, consider the Lorenz system, a classic chaotic system. The code below demonstrates how to set up and solve a large ensemble of Lorenz equations. Doing so in the GPU is as simple as changing the ensemble method to <code>EnsembleGPUArray</code>:</p>
<pre><code class="language-julia">using DiffEqGPU, OrdinaryDiffEq, CUDA
function lorenz&#40;du, u, p, t&#41;
    du&#91;1&#93; &#61; p&#91;1&#93; * &#40;u&#91;2&#93; - u&#91;1&#93;&#41;
    du&#91;2&#93; &#61; u&#91;1&#93; * &#40;p&#91;2&#93; - u&#91;3&#93;&#41; - u&#91;2&#93;
    du&#91;3&#93; &#61; u&#91;1&#93; * u&#91;2&#93; - p&#91;3&#93; * u&#91;3&#93;
end

u0 &#61; Float32&#91;1.0; 0.0; 0.0&#93;
tspan &#61; &#40;0.0f0, 100.0f0&#41;
p &#61; &#91;10.0f0, 28.0f0, 8 / 3.0f0&#93;
prob &#61; ODEProblem&#40;lorenz, u0, tspan, p&#41;
prob_func &#61; function &#40;prob, i, repeat&#41;
    remake&#40;prob, p &#61; rand&#40;Float32, 3&#41; .* p&#41;
end
monteprob &#61; EnsembleProblem&#40;prob, prob_func &#61; prob_func, safetycopy &#61; false&#41;

# CPU-based
sol &#61; solve&#40;monteprob, Tsit5&#40;&#41;, EnsembleThreads&#40;&#41;,
            trajectories &#61; 10_000, saveat &#61; 1.0f0&#41;;

# GPU-based
sol &#61; solve&#40;monteprob, Tsit5&#40;&#41;, EnsembleGPUArray&#40;CUDA.CUDABackend&#40;&#41;&#41;,
            trajectories &#61; 10_000, saveat &#61; 1.0f0&#41;;</code></pre>
<p>The use of <code>EnsembleGPUArray</code> has a bit of overhead because it parallelizes at the level of array operations. It is also possible to execute the entire solver on the GPU by using <code>EnsembleGPUKernel</code>, which offers even better performance, albeit at the the cost of some flexibility. For example, it requires using special solvers and writing the the problem in out-of-place form:</p>
<pre><code class="language-julia">using DiffEqGPU, OrdinaryDiffEq, StaticArrays, CUDA

function lorenz2&#40;u, p, t&#41;
    σ &#61; p&#91;1&#93;
    ρ &#61; p&#91;2&#93;
    β &#61; p&#91;3&#93;
    du1 &#61; σ * &#40;u&#91;2&#93; - u&#91;1&#93;&#41;
    du2 &#61; u&#91;1&#93; * &#40;ρ - u&#91;3&#93;&#41; - u&#91;2&#93;
    du3 &#61; u&#91;1&#93; * u&#91;2&#93; - β * u&#91;3&#93;
    return SVector&#123;3&#125;&#40;du1, du2, du3&#41;
end

u0 &#61; @SVector &#91;1.0f0; 0.0f0; 0.0f0&#93;
tspan &#61; &#40;0.0f0, 10.0f0&#41;
p &#61; @SVector &#91;10.0f0, 28.0f0, 8 / 3.0f0&#93;
prob &#61; ODEProblem&#123;false&#125;&#40;lorenz2, u0, tspan, p&#41;
prob_func &#61; function &#40;prob, i, repeat&#41;
    remake&#40;prob, p &#61; &#40;@SVector rand&#40;Float32, 3&#41;&#41; .* p&#41;
end
monteprob &#61; EnsembleProblem&#40;prob, prob_func &#61; prob_func, safetycopy &#61; false&#41;
sol &#61; solve&#40;monteprob, GPUTsit5&#40;&#41;, EnsembleGPUKernel&#40;CUDA.CUDABackend&#40;&#41;&#41;,
            trajectories &#61; 10_000, saveat &#61; 1.0f0&#41;</code></pre>
<h2 id="oceananigansjl_simulating_fluid_dynamics"><a href="#oceananigansjl_simulating_fluid_dynamics" class="header-anchor">Oceananigans.jl: Simulating Fluid Dynamics</a></h2>
<p><strong><a href="https://github.com/CliMA/Oceananigans.jl">Oceananigans.jl</a></strong> is a fast, friendly, and flexible software package for the numerical simulation of incompressible, stratified flows in the ocean, atmosphere, and laboratory, written in Julia.</p>
<p>GPU support in Oceananigans.jl is built on top of KernelAbstractions.jl, and simply requires the user to specify the <code>GPU&#40;&#41;</code> backend when creating the grid:</p>
<pre><code class="language-julia">using Oceananigans

grid &#61; RectilinearGrid&#40;GPU&#40;&#41;, size&#61;&#40;128, 128&#41;, x&#61;&#40;0, 2π&#41;, y&#61;&#40;0, 2π&#41;,
                       topology&#61;&#40;Periodic, Periodic, Flat&#41;&#41;
model &#61; NonhydrostaticModel&#40;; grid, advection&#61;WENO&#40;&#41;&#41;
ϵ&#40;x, y&#41; &#61; 2rand&#40;&#41; - 1
set&#33;&#40;model, u&#61;ϵ, v&#61;ϵ&#41;
simulation &#61; Simulation&#40;model; Δt&#61;0.01, stop_time&#61;4&#41;
run&#33;&#40;simulation&#41;</code></pre>
<!-- CONTENT ENDS HERE -->
      </main>
    </div> <!-- class="container" -->

    
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>

<!-- Languages -->
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/languages/julia.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/languages/julia-repl.min.js"></script>

<script>hljs.highlightAll();</script>

    

    <footer id=footer class="mt-auto text-center text-muted">
        <div class=container>Made with <a href=https://franklinjl.org>Franklin.jl</a> and <a href=https://julialang.org>the Julia programming language</a>.</div>
    </footer>

    <!-- FEATHER -->
    <script src="https://cdn.jsdelivr.net/npm/feather-icons@4.29.2/dist/feather.min.js"></script>
    <script>feather.replace()</script>

    <!-- BOOTSTRAP -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/js/bootstrap.bundle.min.js"></script>

    <!-- GOOGLE ANALYTICS -->
    <script>
    window.ga = window.ga || function() {
        (ga.q = ga.q || []).push(arguments)
    };
    ga.l = +new Date;
    ga('create', 'UA-154489943-1', 'auto');
    ga('send', 'pageview');
    </script>
    <script async src=https://www.google-analytics.com/analytics.js></script>

  </body>
</html>
