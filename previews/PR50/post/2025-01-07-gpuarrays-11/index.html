<!doctype html>
<html lang="en" class=h-100>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
  <meta content="index, follow" name=robots>
  <link rel="icon" href="/previews/PR50/assets/favicon.ico">
  <link rel="alternate" type="application/rss+xml" href="/previews/PR50/post/index.xml" title="RSS Feed for JuliaGPU">

  <link rel="stylesheet" href="/previews/PR50/css/bootstrap.min.css">
  
   <link rel="stylesheet" href="/previews/PR50/libs/highlight/github.min.css">
 

  <style>
 .hljs {
     padding: 0;
     background: 0 0
 }
.container {
   max-width: 700px
}

#nav-border {
   border-bottom: 1px solid #212529
}

#main {
   margin-top: 1em;
   margin-bottom: 4em
}

#home-jumbotron {
   background-color: inherit
}

#footer .container {
   padding: 1em 0
}

#footer a {
   color: inherit;
   text-decoration: underline
}

.font-125 {
   font-size: 125%
}

.tag-btn {
   margin-bottom: .3em
}

pre {
   background-color: #f5f5f5;
   border: 1px solid #ccc;
   border-radius: 4px;
   padding: 16px
}

pre code {
   padding: 0;
   font-size: inherit;
   color: inherit;
   background-color: transparent;
   border-radius: 0
}

code {
   padding: 2px 4px;
   font-size: 90%;
   color: #c7254e;
   background-color: #f9f2f4;
   border-radius: 4px
}

img,
iframe,
embed,
video,
audio {
   max-width: 100%
}

.card-img,
.card-img-top,
.card-img-bottom {
   width: initial
}

#main h1>a, #main h2>a, #main h3>a {
   color: inherit;
   text-decoration: none;
}

li p {
   margin: 0
}

</style>


  
  
    <title>GPUArrays v11: Port to KernelAbstractions.jl â‹… JuliaGPU</title>
  
</head>
<body class="d-flex flex-column h-100">
  <div id=nav-border class=container>
    <nav class="navbar navbar-expand-lg navbar-light justify-content-center">
        <ul class=navbar-nav>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/"><i data-feather=home></i>Home</a>
            </li>
            <li class="nav-item active"><a class=nav-link href="/previews/PR50/post/"><i data-feather=file-text></i>Blog</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/learn/"><i data-feather=book-open></i>Learn</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/cuda/">CUDA</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/rocm/">ROCm</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/oneapi/">oneAPI</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/metal/">Metal</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR50/other/">Other</a>
            </li>
        </ul>
    </nav>
</div>


  <div class="container">
    <main id=main>

    
      <!-- make sure to generate a Hugo-era URI at the root, redirecting to /post/.... -->
      

      <h1>GPUArrays v11: Port to KernelAbstractions.jl</h1>
      <i data-feather=calendar></i>
<time datetime=2025-1-7>Jan 7, 2025</time><br>
<i data-feather=edit-2></i>
Tim Besard


      <br><br>
    
<!-- Content appended here -->

<p>The latest version of GPUArrays.jl involved a port of all vendor-neutral kernels to KernelAbstractions.jl. This should make it easier to add new functionality and improve the performance of existing kernels.</p>
<h2 id="vendor-neutral_kernel_dsl"><a href="#vendor-neutral_kernel_dsl" class="header-anchor">Vendor-neutral kernel DSL</a></h2>
<p>Back in the day, we created GPUArrays.jl to avoid having to write separate kernels for each GPU back-end, by relying on a very simple vendor-neutral domain-specific language &#40;DSL&#41; that could be translated very easily to the back-end&#39;s native kernel language. As a simple example, the following kernel was used to compute the adjoint of a vector:</p>
<pre><code class="language-julia">function LinearAlgebra.adjoint&#33;&#40;B::AbstractGPUMatrix, A::AbstractGPUVector&#41;
    gpu_call&#40;B, A&#41; do ctx, B, A
        idx &#61; @linearidx A
        @inbounds B&#91;1, idx&#93; &#61; adjoint&#40;A&#91;idx&#93;&#41;
        return
    end
    return B
end</code></pre>
<p>This DSL was designed almost a decade ago, by <a href="https://github.com/SimonDanisch">Simon Danisch</a>, and has served us well&#33; Since then, KernelAbstractions.jl has been developed by <a href="https://github.com/vchuravy/">Valentin Churavy</a>, providing a more principled and powerful DSL. With many application developers switching to KernelAbstractions.jl, it was time to port GPUArrays.jl to this new DSL as well.</p>
<p>Thanks to the tireless work by <a href="https://github.com/leios">James Schloss</a>, <strong>GPUArrays.jl v11 now uses KernelAbstractions.jl for all vendor-neutral kernels</strong>. The aforementioned <code>adjoint&#33;</code> kernel now looks like this:</p>
<pre><code class="language-julia">function LinearAlgebra.adjoint&#33;&#40;B::AbstractGPUMatrix, A::AbstractGPUVector&#41;
    @kernel function adjoint_kernel&#33;&#40;B, A&#41;
        idx &#61; @index&#40;Global, Linear&#41;
        @inbounds B&#91;1, idx&#93; &#61; adjoint&#40;A&#91;idx&#93;&#41;
    end
    adjoint_kernel&#33;&#40;get_backend&#40;A&#41;&#41;&#40;B, A; ndrange&#61;size&#40;A&#41;&#41;
    return B
end</code></pre>
<p>As shown above, the KernelAbstractions.jl DSL is very similar to the old DSL, but it provides more flexibility and power &#40;e.g., support for atomics through Atomix.jl&#41;. In addition, many more users are familiar with KernelAbstractions.jl, making it easier for them to contribute to GPUArrays.jl. A good first step here would be to port some of the vendor-specific kernels from CUDA.jl to GPUArrays.jl, making them available to all GPU back-ends. If you are interested in contributing, please reach out&#33;</p>
<p>That said, the change is not without its challenges. The added flexibility offered by KernelAbstractions.jl with respect to indexing currently results in <strong>certain kernels being slower than before</strong>, specifically when there is not much computational complexity to amortise the cost of indexing &#40;e.g., when doing very simple broadcasts&#41;. <a href="https://github.com/JuliaGPU/GPUArrays.jl/issues/565">We are working on improving this</a>, but it will take some time. Not to hold back the rest of the JuliaGPU ecosystem, we are releasing despite these performance issues. It&#39;s recommended to carefully benchmark your application after upgrading to v11, and to report any performance regressions</p>
<h2 id="back-end_package_versions"><a href="#back-end_package_versions" class="header-anchor">Back-end package versions</a></h2>
<p>As GPUArrays.jl is not a direct dependency of most applications, the update will be pulled in by the following back-end package versions &#40;some of which may not be released yet&#41;:</p>
<ul>
<li><p>CUDA.jl v5.6</p>
</li>
<li><p>Metal.jl v1.5</p>
</li>
<li><p>oneAPI.jl v2.0</p>
</li>
<li><p>AMDGPU.jl v1.1</p>
</li>
</ul>
<!-- CONTENT ENDS HERE -->
      </main>
    </div> <!-- class="container" -->


    
    
        <script src="/previews/PR50/libs/highlight/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

    

    <footer id=footer class="mt-auto text-center text-muted">
        <div class=container>Made with <a href=https://franklinjl.org>Franklin.jl</a> and <a href=https://julialang.org>the Julia programming language</a>.</div>
    </footer>

    <!-- FEATHER -->
    <script src="/previews/PR50/libs/feather/feather.min.js"></script>
    <script>feather.replace()</script>

    <!-- GOOGLE ANALYTICS -->
    <script>
    window.ga = window.ga || function() {
        (ga.q = ga.q || []).push(arguments)
    };
    ga.l = +new Date;
    ga('create', 'UA-154489943-1', 'auto');
    ga('send', 'pageview');
    </script>
    <script async src=https://www.google-analytics.com/analytics.js></script>

  </body>
</html>
