<!doctype html>
<html lang="en" class=h-100>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
  <meta content="index, follow" name=robots>
  <link rel="icon" href="/previews/PR39/assets/favicon.ico">
  <link rel="alternate" type="application/rss+xml" href="/previews/PR39/post/index.xml" title="RSS Feed for JuliaGPU">

  <link rel="stylesheet" href="/previews/PR39/css/bootstrap.min.css">
  
   <link rel="stylesheet" href="/previews/PR39/libs/highlight/github.min.css">
 

  <style>
 .hljs {
     padding: 0;
     background: 0 0
 }
.container {
   max-width: 700px
}

#nav-border {
   border-bottom: 1px solid #212529
}

#main {
   margin-top: 1em;
   margin-bottom: 4em
}

#home-jumbotron {
   background-color: inherit
}

#footer .container {
   padding: 1em 0
}

#footer a {
   color: inherit;
   text-decoration: underline
}

.font-125 {
   font-size: 125%
}

.tag-btn {
   margin-bottom: .3em
}

pre {
   background-color: #f5f5f5;
   border: 1px solid #ccc;
   border-radius: 4px;
   padding: 16px
}

pre code {
   padding: 0;
   font-size: inherit;
   color: inherit;
   background-color: transparent;
   border-radius: 0
}

code {
   padding: 2px 4px;
   font-size: 90%;
   color: #c7254e;
   background-color: #f9f2f4;
   border-radius: 4px
}

img,
iframe,
embed,
video,
audio {
   max-width: 100%
}

.card-img,
.card-img-top,
.card-img-bottom {
   width: initial
}

#main h1>a, #main h2>a, #main h3>a {
   color: inherit;
   text-decoration: none;
}

li p {
   margin: 0
}

</style>


  
  
    <title>Paper: Flexible Performant GEMM Kernels on GPUs â‹… JuliaGPU</title>
  
</head>
<body class="d-flex flex-column h-100">
  <div id=nav-border class=container>
    <nav class="navbar navbar-expand-lg navbar-light justify-content-center">
        <ul class=navbar-nav>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/"><i data-feather=home></i>Home</a>
            </li>
            <li class="nav-item active"><a class=nav-link href="/previews/PR39/post/"><i data-feather=file-text></i>Blog</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/learn/"><i data-feather=book-open></i>Learn</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/cuda/">CUDA</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/rocm/">ROCm</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/oneapi/">oneAPI</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/metal/">Metal</a>
            </li>
            <li class="nav-item "><a class=nav-link href="/previews/PR39/other/">Other</a>
            </li>
        </ul>
    </nav>
</div>


  <div class="container">
    <main id=main>

    
      <!-- make sure to generate a Hugo-era URI at the root, redirecting to /post/.... -->
      

      <h1>Paper: Flexible Performant GEMM Kernels on GPUs</h1>
      <i data-feather=calendar></i>
<time datetime=2020-9-28>Sep 28, 2020</time><br>
<i data-feather=edit-2></i>
Thomas Faingnaert, Tim Besard, Bjorn De Sutter


      <br><br>
    
<!-- Content appended here -->

<p>General Matrix Multiplication or GEMM kernels take center place in high performance computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as NVIDIA&#39;s Tensor Cores. In this paper we show how it is possible to program these accelerators from Julia, and present abstractions and interfaces that allow to do so efficiently without sacrificing performance.</p>
<p>A pre-print of the paper has been published on arXiv: <a href="https://arxiv.org/abs/2009.12263">arXiv:2009.12263</a>. <br/> The source code can be found on GitHub: <a href="https://github.com/thomasfaingnaert/GemmKernels.jl">thomasfaingnaert/GemmKernels.jl</a>.</p>
<p>With the APIs from GemmKernels.jl, it is possible to instantiate GEMM kernels that perform in the same ball park as, and sometimes even outperform state-of-the-art libraries like CUBLAS and CUTLASS. For example, performing a mixed-precision multiplication of two 16-bit matrixes into a 32-bit accumulator &#40;on different combinations of layouts&#41;:</p>
<figure>
  <img src="/previews/PR39/post/2020-09-28-gemmkernels/mixed_precision.png" alt="Performance of mixed-precision GEMM">
</figure>

<p>The APIs are also highly flexible and allow customization of each step, e.g., to apply the activation function <code>max&#40;x, 0&#41;</code> for implementing a rectified linear unit &#40;ReLU&#41;:</p>
<pre><code class="language-julia">a &#61; CuArray&#40;rand&#40;Float16, &#40;M, K&#41;&#41;&#41;
b &#61; CuArray&#40;rand&#40;Float16, &#40;K, N&#41;&#41;&#41;
c &#61; CuArray&#40;rand&#40;Float32, &#40;M, N&#41;&#41;&#41;
d &#61; similar&#40;c&#41;

conf &#61; GemmKernels.get_config&#40;
    gemm_shape &#61; &#40;M &#61; M, N &#61; N, K &#61; K&#41;,
    operator &#61; Operator.WMMAOp&#123;16, 16, 16&#125;,
    global_a_layout &#61; Layout.AlignedColMajor&#123;Float16&#125;,
    global_c_layout &#61; Layout.AlignedColMajor&#123;Float32&#125;&#41;

GemmKernels.matmul&#40;
    a, b, c, d, conf;
    transform_regs_to_shared_d &#61; Transform.Elementwise&#40;x -&gt; max&#40;x, 0&#41;&#41;&#41;</code></pre>
<p>The GemmKernels.jl framework is written entirely in Julia, demonstrating the high-performance GPU programming capabilities of this language, but at the same time keeping the research accessible and easy to modify or repurpose by other Julia developers.</p>
<!-- CONTENT ENDS HERE -->
      </main>
    </div> <!-- class="container" -->


    
    
        <script src="/previews/PR39/libs/highlight/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

    

    <footer id=footer class="mt-auto text-center text-muted">
        <div class=container>Made with <a href=https://franklinjl.org>Franklin.jl</a> and <a href=https://julialang.org>the Julia programming language</a>.</div>
    </footer>

    <!-- FEATHER -->
    <script src="/previews/PR39/libs/feather/feather.min.js"></script>
    <script>feather.replace()</script>

    <!-- GOOGLE ANALYTICS -->
    <script>
    window.ga = window.ga || function() {
        (ga.q = ga.q || []).push(arguments)
    };
    ga.l = +new Date;
    ga('create', 'UA-154489943-1', 'auto');
    ga('send', 'pageview');
    </script>
    <script async src=https://www.google-analytics.com/analytics.js></script>

  </body>
</html>
