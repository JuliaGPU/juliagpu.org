<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta content="index, follow" name=robots><meta name=generator content="Hugo 0.75.1"><link rel=stylesheet href=https://juliagpu.org/css/bootstrap.min.css><link rel=stylesheet href=/highlight.css><script src=/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><style>.hljs{padding:0;background:0 0}</style><title>CUDA.jl 2.4 and 2.5 Â· JuliaGPU</title><style>.container{max-width:700px}#nav-border{border-bottom:1px solid #212529}#main{margin-top:1em;margin-bottom:4em}#home-jumbotron{background-color:inherit}#footer .container{padding:1em 0}#footer a{color:inherit;text-decoration:underline}.font-125{font-size:125%}.tag-btn{margin-bottom:.3em}pre{background-color:#f5f5f5;border:1px solid #ccc;border-radius:4px;padding:16px}pre code{padding:0;font-size:inherit;color:inherit;background-color:transparent;border-radius:0}code{padding:2px 4px;font-size:90%;color:#c7254e;background-color:#f9f2f4;border-radius:4px}img,iframe,embed,video,audio{max-width:100%}.card-img,.card-img-top,.card-img-bottom{width:initial}</style></head><body class="d-flex flex-column h-100"><div id=nav-border class=container><nav class="navbar navbar-expand-lg navbar-light justify-content-center"><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/><i data-feather=home></i>Home</a></li><li class="nav-item active"><a class=nav-link href=/post/><i data-feather=file-text></i>Blog</a></li><li class=nav-item><a class=nav-link href=/learn/><i data-feather=book-open></i>Learn</a></li><li class=nav-item><a class=nav-link href=/cuda/>NVIDIA CUDA</a></li><li class=nav-item><a class=nav-link href=/rocm/>AMD ROCm</a></li><li class=nav-item><a class=nav-link href=/oneapi/>Intel oneAPI</a></li><li class=nav-item><a class=nav-link href=/other/>Other</a></li></ul></nav></div><div class=container><main id=main><h1>CUDA.jl 2.4 and 2.5</h1><i data-feather=calendar></i><time datetime=2021-01-08>Jan 8, 2021</time><br><i data-feather=edit-2></i>Tim Besard<br><br><p>CUDA.jl v2.4 and v2.5 are two almost-identical feature releases, respectively for Julia 1.5
and 1.6. These releases feature a greatly improved <code>findmin</code> and <code>findmax</code> kernels, an
improved interface for kernel introspection, support for CUDA 11.2, and of course many bug
fixes.</p><h2 id=improved-findmin-and-findmax-kernels>Improved <code>findmin</code> and <code>findmax</code> kernels</h2><p>Thanks to <a href=https://github.com/tkf>@tkf</a> and <a href=https://github.com/Ellipse0934>@Ellipse0934</a>,
CUDA.jl now <a href=https://github.com/JuliaGPU/CUDA.jl/pull/576>uses a single-pass kernel for finding the minimum or maximum item in a
CuArray</a>. This fixes compatibility with
<code>NaN</code>-valued elements, while on average improving performance. Depending on the rank, shape
and size of the array these improvements vary from a minor regression to order-of-magnitude
improvements.</p><h2 id=new-kernel-introspection-interface>New kernel introspection interface</h2><p>It is now possible to obtain a compiled-but-not-launched kernel by passing the
<code>launch=false</code> keyword to <code>@cuda</code>. This is useful when you want to reflect, e.g., query the
amount of registers, or other kernel properties:</p><pre><code class=language-julia>julia&gt; kernel = @cuda launch=false identity(nothing)
CUDA.HostKernel{identity,Tuple{Nothing}}(...)

julia&gt; CUDA.registers(kernel)
4
</code></pre><p>The old API is still available, and will even be extended in future versions of CUDA.jl for
the purpose of compiling device functions (not kernels):</p><pre><code class=language-julia>julia&gt; kernel = cufunction(identity, Tuple{Nothing})
CUDA.HostKernel{identity,Tuple{Nothing}}(...)
</code></pre><h2 id=support-for-cuda-112>Support for CUDA 11.2</h2><p>CUDA.jl now supports the latest version of CUDA, version 11.2. Because CUDNN and CUTENSOR
are not compatible with this release yet, CUDA.jl won&rsquo;t automatically switch to it unless
you explicitly request so:</p><pre><code class=language-julia>julia&gt; ENV[&quot;JULIA_CUDA_VERSION&quot;] = &quot;11.2&quot;
&quot;11.2&quot;

julia&gt; using CUDA

julia&gt; CUDA.versioninfo()
CUDA toolkit 11.2.0, artifact installation
CUDA driver 11.2.0
NVIDIA driver 460.27.4
</code></pre><p>Alternatively, if you disable use of artifacts through <code>JULIA_CUDA_USE_BINARYBUILDER=false</code>,
CUDA 11.2 can be picked up from your local system.</p><h2 id=future-developments>Future developments</h2><p>Due to upstream compiler changes, CUDA.jl 2.4 is expected to be the last release compatible
with Julia 1.5. Patch releases are still possible, but are not automatic: If you need a
specific bugfix from a future CUDA.jl release, create an issue or PR to backport the change.</p></main></div><footer id=footer class="mt-auto text-center text-muted"><div class=container>Made with <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/zwbetz-gh/vanilla-bootstrap-hugo-theme>Vanilla</a></div></footer><script src=https://juliagpu.org/js/feather.min.js></script><script>feather.replace()</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-154489943-1','auto');ga('send','pageview');</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>